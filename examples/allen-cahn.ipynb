{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(current_dir), '.'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import pinns\n",
    "\n",
    "# For cleaner output.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will solve problem from https://arxiv.org/pdf/2111.02801:\n",
    "\n",
    "Given domain $[0, T] \\times [A, B]$, and functions $f(x)$, $g_1(t)$ Ð¸ $g_2(t)$, find such $u(t, x)$ so that\n",
    "\n",
    "$$\\frac{\\partial u}{\\partial t} = D \\frac{\\partial^2 u}{\\partial x^2} + 5(u - u^3)$$\n",
    "$$u(0, x) = f(x), \\quad u(t, A) = g_1(t), \\quad u(t, B) = g_2(t)$$\n",
    "\n",
    "As in paper, we fix domain as $[0, 1] \\times [-1, 1]$, diffusion coefficient $D = 0.001$ and\n",
    "\n",
    "$$f(x) = x^2 \\cos(\\pi x) \\quad g_1(t) = g_2(t) = -1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in diffusion problem, we assume that boundary values are given as finite collection of measurements and stored on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinns.samplers import RandomRectangularSampler, ConstantSampler, DataSampler\n",
    "\n",
    "path = './data/allen-cahn/'\n",
    "\n",
    "\n",
    "''' -- CONSTRAINTS -- '''\n",
    "\n",
    "\n",
    "def get_data(path):\n",
    "    init = torch.tensor(np.load(path + 'init_data.npy'))\n",
    "    left = torch.tensor(np.load(path + 'left_data.npy'))\n",
    "    right = torch.tensor(np.load(path + 'right_data.npy'))\n",
    "    \n",
    "    return ([init[:,  :2], left[:,  :2], right[:,  :2]], \n",
    "            [init[:, [2]], left[:, [2]], right[:, [2]]])\n",
    "\n",
    "pts, data = get_data(path)\n",
    "constraints_sampler = ConstantSampler((pts, data))\n",
    "\n",
    "\n",
    "''' -- COLLOCATION -- '''\n",
    "\n",
    "\n",
    "domain = {'t': [0, 1], 'x': [-1, 1]}\n",
    "collocation_sampler = RandomRectangularSampler(domain, 2048)\n",
    "\n",
    "\n",
    "''' -- VALIDATION DATA -- '''\n",
    "\n",
    "\n",
    "test_data_sampler = DataSampler(path + 'solution.npy', 512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinns.derivatives import Derivative\n",
    "\n",
    "d = Derivative(method='autograd')\n",
    "\n",
    "def loss(\n",
    "    cstr_pts, cstr_pred, cstr_vals,\n",
    "    coll_pts, coll_pred,\n",
    "    D = 0.001\n",
    "    ):\n",
    "    \n",
    "    # We do not need left and right because we are solving \n",
    "    # Dirichlet problem and we just compare predictions and \n",
    "    # solution. If we solve Cauchy or Robin problem, we \n",
    "    # need to calculate derivatives at boundary points.\n",
    "    \n",
    "    init_pts, left_pts, right_pts = cstr_pts\n",
    "    init_pred, left_pred, right_pred = cstr_pred\n",
    "    init_vals, left_vals, right_vals = cstr_vals\n",
    "    \n",
    "    t, x = coll_pts['t'], coll_pts['x']\n",
    "    \n",
    "    def initial_loss():\n",
    "        return torch.mean(torch.square(init_pred - init_vals))\n",
    "    \n",
    "    def left_loss():\n",
    "        return torch.mean(torch.square(left_pred - left_vals))\n",
    "    \n",
    "    def right_loss():\n",
    "        return torch.mean(torch.square(right_pred - right_vals))\n",
    "    \n",
    "    def pde_loss(u, t, x):\n",
    "        ut  = d(u,  t)\n",
    "        uxx = d(u,  x, orders = 2)\n",
    "        return torch.mean(torch.square(ut - D * uxx - 5 * (u - u**3)))\n",
    "    \n",
    "    return (\n",
    "        initial_loss(), \n",
    "        left_loss(), \n",
    "        right_loss(), \n",
    "        pde_loss(coll_pred, t, x)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinns import Trainer\n",
    "from pinns.models import FF\n",
    "from pinns.activations import Sin\n",
    "from pinns.optimizers import Adam\n",
    "from pinns.errors import l2 as metric\n",
    "\n",
    "pinn = FF([2] + [32, 32] + [1], activ=Sin())\n",
    "\n",
    "adam = Adam(pinn, lr = 1e-2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    loss,\n",
    "    pinn,\n",
    "    constraints_sampler,\n",
    "    collocation_sampler,\n",
    "    loss_coefs = [0.75]*3 + [0.25],\n",
    "    test_points_sampler = test_data_sampler\n",
    ")\n",
    "\n",
    "num_iters = 5000\n",
    "save_every = 25\n",
    "\n",
    "def make_plot():\n",
    "    if trainer.iter == 0 or trainer.iter % save_every == 0 or trainer.iter == num_iters:\n",
    "        preds = pinn.predict(test_data_sampler(full=True)[0]).detach()\n",
    "        np.save(f'./.temp/{trainer.iter}.npy', preds.numpy())\n",
    "\n",
    "trainer.train(\n",
    "    num_iters=num_iters,\n",
    "    optimizers=[(0, adam)],\n",
    "    validate_every=1,\n",
    "    error_metric=metric,\n",
    "    at_training_start_callbacks=[make_plot],\n",
    "    at_epoch_end_callbacks=[make_plot],\n",
    "    at_training_end_callbacks=[make_plot]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot(error_names = ['L2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know the shape of test data.\n",
    "Nt, Nx = 101, 201\n",
    "pts, values = test_data_sampler(full=True)\n",
    "\n",
    "pts = [\n",
    "    pts[:,0].reshape(Nt, Nx),\n",
    "    pts[:,1].reshape(Nt, Nx)\n",
    "]\n",
    "values = values.reshape(Nt, Nx)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "preds = pinn.predict(test_data_sampler(full=True)[0]).detach().reshape(Nt, Nx)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(pts[1], pts[0], preds, cmap='viridis')\n",
    "# ax.plot_surface(pts[1], pts[0], values, cmap='viridis')\n",
    "\n",
    "cstr_pts, cstr_vals = constraints_sampler()\n",
    "stacked_pts = torch.cat([torch.hstack([t[:, [1]], t[:, [0]]]) for t in cstr_pts])\n",
    "stacked_vals = torch.cat(cstr_vals)\n",
    "constraints = torch.hstack([stacked_pts, stacked_vals.reshape(-1, 1)]).T\n",
    "\n",
    "ax.scatter3D(*constraints, color='r', s=10)\n",
    "# ax.view_init(80, -120)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imageio\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "def save_animation(files, path, duration=5, fps=60, loop=0, type='mp4', processors=2, ):\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    def plot(i):\n",
    "        predictions = np.load(files[i]).reshape(Nt, Nx)\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        # Set plot limits and labels\n",
    "        ax.set_xlim(-1, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        surface = ax.plot_surface(pts[1], pts[0], predictions, cmap='viridis')\n",
    "        scatter = ax.scatter3D(*constraints, color='r', s=10)\n",
    "        fig.savefig(f'./.temp/frame_{i}.png', dpi=300)\n",
    "        fig.clear()\n",
    "        \n",
    "    # Number of frames\n",
    "    num_frames = len(files)\n",
    "\n",
    "    # Parallelize the plotting function\n",
    "    Parallel(n_jobs=processors, verbose=10)(delayed(plot)(i) for i in range(num_frames))\n",
    "    \n",
    "    if type == 'mp4':\n",
    "        writer = imageio.get_writer(path, fps=fps)\n",
    "        for i in range(len(files)):\n",
    "            writer.append_data(imageio.imread(f'./.temp/frame_{i}.png'))\n",
    "        writer.close()\n",
    "        \n",
    "    if type == 'gif':\n",
    "        imgs = [Image.open(f'./.temp/frame_{i}.png') for i in range(len(files))]\n",
    "        imgs[0].save(path, save_all=True, append_images=imgs[1:], duration=duration, fps=fps, loop=loop)\n",
    "    \n",
    "files = [f'./.temp/{i}.npy' for i in range(0, trainer.iter, save_every)]\n",
    "save_animation(files, './.results/allen cahn animation.gif', type='gif', processors=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
